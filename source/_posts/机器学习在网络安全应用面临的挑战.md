---
title: 机器学习在网络安全应用面临的挑战
date: 2022-02-22 22:22:22
categories:
	-网络安全
	-AI检测
---

### 机器学习是网络安全的答案吗

随着计算机计算能力的不断升级，机器学习尤其是深度学习发展尤为迅速，再加之资本的推动以及机器学习在CV、NLP等领域的优异表现，网络安全行业的从业者仿佛找到了解决问题的答案。尤其在论文、学术会议上机器学习检测诸多问题时那令人震撼的检测能力，配合完美的检测能力量化指标，更是让机器学习展现出了无限的魅力。

那么机器学习是网络安全的答案吗?或者说网络安全能在机器学习中找到答案吗?网络安全中机器学习好像并没有非常成功的案例，针对一个用有限数据喂出来的一个模型，大家更多的聚焦在模型的问题上，这个误报怎么高？感觉没有规则靠谱啊?模型怎么只是在你自己的数据下精确率这么好呢？模型就给个结果，没有可解释性啊？这一连串的问题都是机器学习在网络安全应用上面临的挑战，也是机器学习工程化面临挑战的缩影。

那我们接下来就从几个方面总结一下机器学习在网络安全应用面临的挑战：

第一、有限的数据，代表偏执的分布

第二、不合理的特征，如盲人摸象

第三、脆弱的算法，难挑重任

第四、美丽的算法背后，需要一个工程化的男人

第五、模型的成长，离不开运维的呵护

第六、机器学习如何走出你的偏见

第七、如果你相信我，可解释化真的就那么重要吗

接下来笔者将结合自己的经理和经验，从这七个方面分别做介绍。

### 有限的数据，代表偏执的分布

在机器学习的研究领域有一句话广为流传，笔者也对此深表认可：数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。由此可见数据和特征对机器学习的重要程度，而作为其中之一的数据，是真实场景的归纳。机器学习应用的数据越贴近真实场景的数据分布，模型和算法才能学习到最贴近真实的知识。

笔者曾经听过一个笑话，说古时候有一个穷人发誓当了皇帝以后，要一个手拿着柿子饼，一个手拿馒头，想怎么吃就怎么吃。可能你会笑这个穷人，都当了皇帝还想着吃柿子饼和馒头，飞禽走兽、山珍海味岂不是随便吃？可是站在穷人的视角，在他接触到的食物中，最好吃的就是馒头和柿子饼，山珍海味他没听过更没见过。

我们回到当前这个问题，模型在训练的过程中只接触过“馒头”和“柿子饼”，但是在检测时遇到"燕窝"和"鱼翅"，他会不会也像这个穷人当了皇帝一样呢？所以对于机器学习模型来说，数据规模一定要满足模型训练的要求。只给有限的数据来训练机器学习模型，最终也会因此数据分布与真实场景分布存在的差异，导致模型失准。

另外机器学习领域还有另外一句话广为流传：garbage in, garbage out ，简称(GIGO)。简言之就是，训练模型的输入数据是垃圾，新练出来的模型也是垃圾。因此训练机器学习模型的数据一定是有价值的，针对监督学习来说，数据的标注一定是准确的。这种高水平的数据训练出来的模型才是有价值的模型。

### 不合理的特征，如盲人摸象

首先我们要明确特征的目的，特征是为了将样本转化成机器学习模型输入。例如图像识别和目标检测等CV问题的特征就是图片的像素，NLP问题的特征就是文本的文字，WAF攻击的特征就是WAF攻击记录的字符，恶意软件的特征就是二进制文件的字节，DGA域名的特征就是域名的字符序列，这样真的对吗？且看笔者分析。

如果我们要检测大象，盲人摸象中的盲人分别摸到了象腿、象鼻子、象耳朵、象身体、象尾巴。不合理的特征就是我们部分盲人摸到的特征来描述大象，就很难通过这些有限的特征对大象进行分类。比如腿像柱子、身体像一栋墙的也可能是犀牛。

而把图像的像素或者文本的文字直接作为特征输入给模型也会有其他的问题。这种直接把样本的所有信息输入到模型的方法，也同时把特征选择的重担也交给了算法，而我们已经说过脆弱的算法，难挑重任。笔者另外一篇博客[为什么LSTM检测DGA是无用功(转载)](https://www.shenyong.zone/2022/03/22/%E4%B8%BA%E4%BB%80%E4%B9%88LSTM%E6%A3%80%E6%B5%8BDGA%E6%98%AF%E6%97%A0%E7%94%A8%E5%8A%9F(%E8%BD%AC%E8%BD%BD)/) 中就已经阐述过，这种通过算法自己选择特征的手段，很容易因为数据偏见导致模型变成捷径学习。举例来说就是检测牛的时候草丛的信息就是具有误导性的信息，天空中的云彩就是冗余的信息。而这些冗余甚至有误导性的信息很可能会被模型作为重要特征并赋予很高的权重，导致没有草丛和云彩的时候，模型的检测能力会变得很差。当然我们可以通过扩充数据集、对抗学习等方法降低捷径学习的影响，但是其成本也是巨大的。

![勇敢牛牛](机器学习在网络安全应用面临的挑战/勇敢牛牛.jpg)

同样的问题也会出现在AI在网络安全的应用上，Raff et al 等作者的 “Malware Detection by Eating a Whole EXE” 使用二进制文件本身作为输入，试图利用卷积网络从 010101 这样的原始字节码特征空间构建一个端到端的恶意软件静态检测分类模型 malconv，它在自己论文的测试集上可以达到 90% 以上的 AUC。然而，抛开其对新样本和对抗样本检测时极不稳定的表现，“DeepMalNet: Evaluating shallow  and deep networks for static PE malware detection” 这篇文章引入新的测试集对比了 malconv 等多个深度模型以及论文作者自建的随机森林模型后发现，通过手工构建特征工程的随机森林模型也几乎可以达到并超过 malconv的效果。究其原因，卷积网络在原始字节码上并不会学习到合适的特征空间，论文中展示的有效性更多是碰巧的结果。Fireeye 的研究人员 Coull et al 的文章 “Activation Analysis of a Byte-Based Deep Neural Network for Malware Classification”表明了malconv的卷积结果其实是把静态二进制文件的文件头信息当作当作主导特征，而由指令跳转组合对模型预测分类的权重极小，其后续改进 EMBER malconv也延续了类似特性，具体的分析和解释可以参见 Bose et al “Explaining AI for Malware Detection: Analysis of Mechanisms of MalConv”。

### 脆弱的算法，难挑重任

算法很多时候是论文中以及学术会议上高手巅峰对决的绝招，但其实抛开数据和特征而言，算法的影响是比较有限的。举例来说，作为网络领域的知名数据集[KDD CUP99](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)一直是算法研究中的常见数据集，不同的算法在这个数据集上争芳斗艳。可是如果我们大胆假设这个数据集并没有完全覆盖IDS攻击的范畴，那么这些巅峰对决的算法绝招还能不能代表名门正派呢。

当然我们也不是完全否定算法的作用，例如CNN等深度学习神经网络的出现快速提高了手写数字识别等图像处理领域的检测能力。但是抛开数据和特征的算法就是无本之木、无源之水。因此我们需要在有效且满足规模要求的数据集下，采用是的特征方法训练出来的算法模型，才是一个有价值的模型。

### 美丽的算法背后，需要一个工程化的男人

算法研究人员在一个标准数据集上不断优化算法，最后新的算法的检测能力优于旧的算法，完成了算法的创新。这种算法层面的创新有些时候会忽视算法的工程化问题，因此在美丽的算法背后，需要一个工程化的男人。

以笔者的个人经历为例，曾经笔者在利用机器学习检测安全问题时，需要用到RNN神经网络，然而应用场景的后端语言是C语言，在应用场景下的Python版本是2.6的，而且CPU和内存资源都极为有限。由于项目工期比较紧张，因此非常希望现有的机器学习框架可以支持C语言API的使用，经过九牛二虎之力才找到tensorflow对C语言极为简略的接口，相关的技术博客参见笔者[如何在C语言中使用tensorflow](https://www.shenyong.zone/2020/05/09/%E5%A6%82%E4%BD%95%E5%9C%A8C%E8%AF%AD%E8%A8%80%E4%B8%AD%E4%BD%BF%E7%94%A8tensorflow%EF%BC%88%E4%B8%80%EF%BC%89%E6%A6%82%E8%BF%B0/)的系列内容。笔者当时就在想通过Python和C++两种语言为主题的算法研究怎么能和C语言这种极为常见的后端语言的工程化应用如此割裂?

因此也希望算法优化和更新的同时，也希望行业研究人员可以同时兼顾算法的工程化问题。以安全行业为例，受限于网络安全行业对监测实时性的要求，很多机器学习算法被用来做离线检测，在数据仓库中拿出离线数据，采用以Python为主要语言的机器学习模型进行检测。而在实时流量场景下，受限于Python的检测速度以及C++的依赖和编译等问题，目前在实时流量检测方向依然没有很好的方法。

### 模型的成长，离不开运维的呵护

这里的运维问题是在两个方面体现的，第一个就是机器学习的检测结果输出是否满足安全运维所需的信息；第二个是安全运维人员是否理解机器学习的检测结果。

首先是机器学习的检测结果输出是否满足安全运维所需的信息。受限于机器学习科学家对安全业务有限的理解，因此其主要精力会集中于模型的检测能力。如果出现预测错误，就会损失召回率换精确率。如果模型在实际场景中的误报过高，就会损失精确率换召回率。对于运维的问题关注度不够。比如DGA检测出某个局域网内多台主机存在C&C连接行为，那运营团队就要挨个排查所有可以主机的所有进程和文件，来确定相关主机是否被恶意木马所控制。如果机器学习在网络安全应用的时候不能考量安全运维的问题，那么模型就会成为一个无法迭代更新的孤岛，也会永远成为一个无法验证的黑盒。

其次是安全运维人员是否理解机器学习的检测结果。随着机器学习等智能方法的出现，过去安全运维团队的运维机制、工具框架以及评价手段也要随之更新。比如说机器学习检测模型出现的误报问题，这时候安全运维人员需要和机器学习科学家共同确认误报出现的场景何原因，应采用不限于模型更新的方法来完善机器学习的检测能力。而不是对机器学习科学家说：“你这个模型还不如两条规则来的实在！”或者“你这个模型到底能不能阻断某某攻击类型？”。如果出现这种情况，就意味着安全运维人员在用处理规则的方法处理机器学习，殊不知是因为其没有很好的理解机器学习的检测结果代表的含义。

在这两个原因以外，还有因为机器学习科学家和安全运维人员因为不用的领域知识结构导致的认知差异。这种认知差异也会导致双方在沟通上存在明显的障碍，你说前门楼子，我说胯骨轴子。这就需要双方在丰富自己领域知识的同时，多了解对方的领域的知识，了解其工作方式和主要工作内容。

### 机器学习如何走出你的偏见

笔者的一位素未蒙面的前同事在离职之后，跟前东家洋洋洒洒数千字的文章，其中言辞犀利的指出了三点内容：

其一、数据科学家、领域专家和决策者之间的沟通合作存在明显壁垒；其二、针对机器学习的评估指标不明确且不合理；其三、人力和数据资源的投入不足。这也是当前机器学习工程化应用广泛存在的一些问题。

针对第一点，数据科学家、领域专家和决策者之间的沟通合作存在明显壁垒，这是由于不同的工作导致领域知识存在明显的认知差异，不同的工作也会导致看为题的角度以及侧重点存在不同。至于第二点，笔者后面有单独的章节进行介绍。最后的第三点的原因主要有两个诱因，第一是出数据科学家之外的人不能很好的理解机器学习研究的基本诉求。第二是在不能确定研究产出以及收益的时候，机器学习的资源投入一定是有限的。

针对这个问题，就需要领域专家和决策者在原有的领域知识认知以外，加深对机器学习本质的了解，明确机器学习的特点以及开展研究的主要诉求，并结合现有的数据能力进行阶段化的开展机器学习研究工作。

### 如果你相信我，可解释化真的就那么重要吗

苛求机器学习尤其是深度学习有很好的可解释性，就如同苛求规则和威胁情报可以发现未知威胁和0 day漏洞一下的不合理。机器学习的特点就决定了她在可解释性上与规则和威胁情报存在明显的差距。一个目标检测的深度神经网络很难说清楚他是基于图片中的那些特征点完成了目标检测的任务。

当然目前机器学习的研究人员也在开阵模型可解释性的研究工作，但是这些工作也是在黑盒的基础上进行的有限工作。这也是基于DT决策树的集成学习模型在工程化中广泛应用的原因，因为二叉树的结构可以将模型可视化，并根据特征的重要性选择以及特征的分裂点进行有限的可解释性分析。

因此通过丰富的数据和合理的特征训练有价值的模型，并以结果为导向对机器学习进行评价，或许更为重要。当你的模型检测结果真的让人信服，那么可解释性真的还那么重要吗?